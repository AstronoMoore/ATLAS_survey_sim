Following QUBITS logic:
 - Measure synthetic photometry from spectral database of object type
 - Generate K correction database
 - Run simulation. Done in 2 parts:
 	1. Populates a 'universe' with transients based on randomly input redshifts, relative rate and peak magnitude distributions
 	2. Simulate the survey using the provided cadence, limiting magnitudes, survey volume and weather loss (event recovery?)
 - Plot results from output of run simulation

__________________________________________________________________________________________

QUBITS-lite logic:
 - Generate 17gfo-like lightcurve in ATLAS filters
 - Populate universe with 17gfo-like events, inflating lightcurves to distances out to 100 Mpc
 - Run simulation, but using real observation data (limiting magnitudes, weather data, observational gaps)
 - Run recovery of lightcurves based on observational parameters
 	1. Require 1 detection for triggering, will give higher rate
 	2. Require 2 detections for triggering (reduced need to trigger in principle), will give lower rate
 	
The core idea is we populate a (local) universe with the total number of kilonova events to go off
then see how many we recover with ATLAS. This gives the ATLAS (detection) rate.